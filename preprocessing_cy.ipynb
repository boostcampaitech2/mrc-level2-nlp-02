{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.idea',\n",
       " '.ipynb_checkpoints',\n",
       " 'BoostCamp37',\n",
       " 'boostcamp_ai_pstage1.zip',\n",
       " 'boostcamp_ai_pstage1_mask',\n",
       " 'boost_camp_ai_tech',\n",
       " 'boost_camp_ai_tech_weekly_report',\n",
       " 'changyong93.github.io',\n",
       " 'huggingface_tutorial_with_vscode',\n",
       " 'image-classification-level1-37',\n",
       " 'KaggleStruggle',\n",
       " 'klue-level2-nlp-02',\n",
       " 'lecture-note-python-basics-for-ai',\n",
       " 'mlpractice',\n",
       " 'mrc-level2-nlp-02',\n",
       " 'nanodegree',\n",
       " 'Natural-language-processing-with-chat-bot',\n",
       " 'natural_language_precessing_lectrue',\n",
       " 'paper_code_review',\n",
       " 'project_Analysis-of-small_business-Data',\n",
       " 'project_Brazilian-E-Commerce-Public-Dataset-by-Olist',\n",
       " 'TIL']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_from_disk(\"../dataset/trainset\")\n",
    "import os\n",
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer\n",
    "checkpoint = \"klue/roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "#get vocab\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "#load mecab\n",
    "m = Mecab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesing_context(context):\n",
    "    # context = re.sub(r\"\\\\n\",\" \",context) #모든 data\n",
    "    # context = re.sub(r\"\\'\",\"\",context) #22 특정 문자열 강조를 위해 '문자열'가 사용될 때 \\'문자열\\' 형태로 입력이 되어 있어서 \\를 제거\n",
    "    # context = re.sub(\"[a-zA-Z가-힣 ]+(\\|)[a-zA-Z가-힣]+(\\|)[a-zA-Z가-힣 ]+(.)\",\" \",context) #27 섬네일|left|페데리코 다 몬테펠트로의 구비오 스투디올로의 모습. 제거\n",
    "    ######################### context = re.sub(\"(\\|)[a-zA-Z가-힣]+(\\|)\",\" \",context) #33 |비트겐슈타인| 과 같은 문자열 제거\n",
    "    #필수\n",
    "    # context = re.sub(\"p=(\\d)+\\-(\\d)+|p=(\\d)+\",\"\",context) #37 page 제거\n",
    "    #필수\n",
    "    # context = re.sub(\"(된다)(.){0}\",\"된다.\",context) #43 된다 => 된다.\n",
    "    ######################### context = re.sub(\"(\\*)*\",\"\",context) #43,50 \"*\" => \"\"\n",
    "    # context = re.sub(\"( )+\", \" \", context)\n",
    "\n",
    "    # 애매함\n",
    "    \"\"\"\n",
    "        유지 => 51 : 1942 ~ 43 == 메이저 리그로 ㅣ입단 ==\n",
    "        테스트 => 51 : .414\n",
    "        유지 => 52 : 교리·이조좌랑·사간·부응교·종부시정·이조참의·동부승지·좌부승지·우승지·남양부사·부제학·대사간·좌승지·수찬관·대사성·병조참의·도승지·강원도관찰사·한성부우윤·대사헌·예문관제학·대제학·이조판서·우빈객·좌빈객\n",
    "\n",
    "    \"\"\"\n",
    "    return context\n",
    "#53번부터\n",
    "i=1466\n",
    "print(trainset.context.map(preprocesing_context)[i],\"\\n\")\n",
    "# print(tokenizer.tokenize(trainset.context.map(preprocesing_context)[i]),\"\\n\")\n",
    "# trainset.loc[i]\n",
    "# trainset[trainset.context==trainset.loc[i].context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나리타공항 건설에서 화근이 된 일본 정부의 정책과 그로 인해 발생한 산리즈카 투쟁은 양측에 모두 비참하기만 한 결과를 가져왔다. 이후 공공사업을 둘러싸고 분쟁이 일어나는 현장에서는 “합의형성의 노력을 하지 않은 채 힘에 의지해 사업을 진행하면 힘에 의한 저항을 낳는다”는 자숙을담아 “나리타처럼 되지 말자(成田のようにならないようにしよう )”가 표어가 되었다. \\n\\n내륙에 공항을 건설하면 토지취득 및 소음 문제가 현저하게 발생할 수밖에 없는데, 나리타에서는 산리즈카 투쟁까지 더해져 막대한 손실을 초래했다. 이 교훈으로 이후 일본은 해상 및 원격지에 공항을 건설하는 경향이 커졌고, 이는 일본 공항의 편리성 저하와 비용 증가로 이어졌다.group=주해|그러나 해상에 건설된 간사이 국제공항에도 중핵파가 공항건설공사의 견학선에 방화하는 테러사건(요코하마요트 소형여객선 폭파사건)을 일으킨 바 있다. group=주해|간사이공항 인공섬 건설 총 공사비가 1조 엔임을 처음 들은 세계 공항관계자는 이 막대한 건설비에 통역의 오역이 아닌지 반문하기도 했다. 또한 토지수용과 행정대집행도 신중하게 실시되도록 되었으니, 산리즈카 투쟁은 일본 공공사업 전반에 엄청난 영향을 미친 것이다 \\n\\n나리타 하늘과 대지의 역사관은 국가공무원 종합직 초임자와 나리타공항회사 신입사원 연수에 포함되어 있다. 제2의 나리타를 만들지 않도록 산리즈카 투쟁의 교훈을 살리기 위한 노력이라 한다 \\n\\n한편 개발에 반대하는 주민 측에서도 실력투쟁에서 주민투표 등으로 투쟁방식을 바꾸는 전환점이 되었다 특히 장기간에 걸친 투쟁을 거쳐 이루어진 나리타 공항 문제 심포지엄・나리타 공항 문제 원탁회의는 이후 공공사업 실시 시의 모델 케이스가 되어, 나가라강 하구둑 문제도 원탁회의 방식이 채택되었고, 얀바댐 반대운동을 하던 주민들이 공부하러 나리타 심포지엄을 방문하는 등 일본 전국 각지에서 행해지던 주민운동의 참고사례가 되었다. \\n\\n관제탑 점거사건 등은 일본 국외에도 크게 보도되어 산리즈카 투쟁의 모습은 영화나 음악 등 예술작품의 테마로 사용되었고, 공공사업의 실패사례로서 큰 주목을 받았다. 예컨대 서독에서는 나리타와 같은 시기에 계획된 뮌헨의 공항건설에 있어서 나리타 공항 문제에 대한 철저한 연구분석을 선행했다. 1969년 공항건설을 결정한 바이에른주 정부는 20년간 259회에 이르는 공청회를 개최하여 반대파를 설득했고, 공항계획이 일부 축소되기는 했지만 최종적으로 착공 5년 후인 1992년 5월 프란츠 요제프 슈트라우스 공항이 개항되어 오늘날 유럽 공항의 일각을 이루고 있다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocesing_context(context):\n",
    "    # context = re.sub(r\"\\\\n\",\" \",context) #모든 data\n",
    "    # context = re.sub(r\"\\'\",\"\",context) #22 특정 문자열 강조를 위해 '문자열'가 사용될 때 \\'문자열\\' 형태로 입력이 되어 있어서 \\를 제거\n",
    "    # context = re.sub(\"[a-zA-Z가-힣 ]+(\\|)[a-zA-Z가-힣]+(\\|)[a-zA-Z가-힣 ]+(.)\",\" \",context) #27 섬네일|left|페데리코 다 몬테펠트로의 구비오 스투디올로의 모습. 제거\n",
    "    ######################### context = re.sub(\"(\\|)[a-zA-Z가-힣]+(\\|)\",\" \",context) #33 |비트겐슈타인| 과 같은 문자열 제거\n",
    "    #필수\n",
    "    # context = re.sub(\"p=(\\d)+\\-(\\d)+|p=(\\d)+\",\"\",context) #37 page 제거\n",
    "    #필수\n",
    "    # context = re.sub(\"(된다)(.){0}\",\"된다.\",context) #43 된다 => 된다.\n",
    "    ######################### context = re.sub(\"(\\*)*\",\"\",context) #43,50 \"*\" => \"\"\n",
    "    # context = re.sub(\"( )+\", \" \", context)\n",
    "\n",
    "    # 애매함\n",
    "    \"\"\"\n",
    "        유지 => 51 : 1942 ~ 43 == 메이저 리그로 ㅣ입단 ==\n",
    "        테스트 => 51 : .414\n",
    "        유지 => 52 : 교리·이조좌랑·사간·부응교·종부시정·이조참의·동부승지·좌부승지·우승지·남양부사·부제학·대사간·좌승지·수찬관·대사성·병조참의·도승지·강원도관찰사·한성부우윤·대사헌·예문관제학·대제학·이조판서·우빈객·좌빈객\n",
    "\n",
    "    \"\"\"\n",
    "    return context\n",
    "#53번부터\n",
    "i=1466\n",
    "print(trainset.context.map(preprocesing_context)[i],\"\\n\")\n",
    "# print(tokenizer.tokenize(trainset.context.map(preprocesing_context)[i]),\"\\n\")\n",
    "# trainset.loc[i]\n",
    "# trainset[trainset.context==trainset.loc[i].context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_answers = 0\n",
    "num_unk = 0\n",
    "htmls = \"\"\n",
    "index_list = []\n",
    "for i, answer in enumerate(list(trainset.answers.map(lambda x : x['text'][0]))):\n",
    "    tokens_mecab = m.morphs(answer)\n",
    "    tokens_bert = []\n",
    "    for token_mecab in tokens_mecab:\n",
    "        tokens_bert.extend(tokenizer.tokenize(token_mecab))\n",
    "    if \"[UNK]\" in tokens_bert:\n",
    "        htmls+=\"<p>\"\n",
    "        resotred_answer = restore_word_by_tokens(tokens_bert)\n",
    "        colored_answer = \"\"\n",
    "        for j,s in enumerate(answer):\n",
    "            if s not in resotred_answer:\n",
    "                colored_answer += word_highligt_html(s)\n",
    "            else:\n",
    "                colored_answer += s\n",
    "        htmls +=f\"[{i}] : {colored_answer}\\n<br> >>>>> {resotred_answer}<br> >>>>> {tokens_bert} <br>\"\n",
    "        count_answers+=1\n",
    "        num_unk += tokens_bert.count(\"[UNK]\")\n",
    "        htmls+=\"</p>\"\n",
    "        index_list.append(i)\n",
    "    \n",
    "print(\"UNK가 포함된 answer의 개수: \", count_answers)\n",
    "print(\"UNK 개수: \", num_unk)\n",
    "HTML(htmls)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d4b788d31f1e8a98acbf5edfe42af7a280714d85bd73a1cdc11a1af0199f3f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
