{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjDdziEN_VCt"
   },
   "source": [
    "# 5강) BERT를 활용한 Dense Passage Retrieval 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NWluWk3_VCu"
   },
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5421,
     "status": "ok",
     "timestamp": 1616574100645,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "eGqFS4EEBF_Z",
    "outputId": "b5b5af1d-0d0d-4197-a717-d2fe3ca2528f"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYUkp06Y_VCv"
   },
   "source": [
    "## 데이터셋 로딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMrZa4uql_nx"
   },
   "source": [
    "KorQuAD train 데이터셋을 학습 데이터로 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6098,
     "status": "ok",
     "timestamp": 1616574101330,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "4IUxepuj_VCv",
    "outputId": "6c681d71-4e21-4062-9807-1d975fc901e8"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# dataset = load_dataset(\"squad_kor_v1\")\n",
    "dataset = load_from_disk('../../data/train_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJtECqpB_VCx"
   },
   "source": [
    "## 토크나이저 준비 - Huggingface 제공 tokenizer 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0Fu2WaqpUB8"
   },
   "source": [
    "BERT를 encoder로 사용하므로, hugginface에서 제공하는 \"bert-base-multilingual-cased\" tokenizer를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AoB8BHGDmVIK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "# model_checkpoint = \"klue/roberta-base\"\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8395,
     "status": "ok",
     "timestamp": 1616574103635,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "WPxRvMjdvh4y",
    "outputId": "069dd4b9-760a-450b-ea59-096510005e53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='klue/bert-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "executionInfo": {
     "elapsed": 9195,
     "status": "ok",
     "timestamp": 1616574104440,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "0U7sn3jsu44O",
    "outputId": "afb5de1c-c5d4-420c-d1f1-f69f56c44cd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 미국 상의원 또는 미국 상원 ( United States Senate ) 은 양원제인 미국 의회의 상원이다. [UNK] n [UNK] n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1 / 3씩 상원의원을 새로 선출하여 연방에 보낸다. [UNK] n [UNK] n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할 ( 하원의 법안을 거부할 권한 등 ) 을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션 ( 공공건강보험기관 ) 의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다. 날짜 = 2017 - 02 - 05 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(dataset['train'][0]['context'], padding=\"max_length\", truncation=True)\n",
    "tokenizer.decode(tokenized_input['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpoTleVJjp5x"
   },
   "source": [
    "## Dense encoder (BERT) 학습 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nrxmtmfkRVb"
   },
   "source": [
    "HuggingFace BERT를 활용하여 question encoder, passage encoder 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6b215ZfJ_EOc"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "\n",
    "torch.manual_seed(2021)\n",
    "torch.cuda.manual_seed(2021)\n",
    "np.random.seed(2021)\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-bKwkxTpoje"
   },
   "source": [
    "1) Training Dataset 준비하기 (question, passage pairs)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E_FQ1kcazxge"
   },
   "outputs": [],
   "source": [
    "# Use subset (128 example) of original training dataset \n",
    "# sample_idx = np.random.choice(range(len(dataset['train'])), 128)\n",
    "# training_dataset = dataset['train'][sample_idx]\n",
    "\n",
    "training_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NJZWx1b-613e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "\n",
    "# q_seqs = tokenizer(training_dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt', return_token_type_ids=False)\n",
    "# p_seqs = tokenizer(training_dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt', return_token_type_ids=False)\n",
    "q_seqs = tokenizer(training_dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "p_seqs = tokenizer(training_dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bAplp66Pkayy"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'],\n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwMvVH1e3h99"
   },
   "source": [
    "2) BERT encoder 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW7Oc7Zd9kkm"
   },
   "source": [
    "BertEncoder 모델 정의 후, question encoder, passage encoder에 pre-trained weight 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaPreTrainedModel, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oKKkTlh_l5VL"
   },
   "outputs": [],
   "source": [
    "# class BertEncoder(RobertaPreTrainedModel):\n",
    "class BertEncoder(BertPreTrainedModel):  \n",
    "  def __init__(self, config):\n",
    "    super(BertEncoder, self).__init__(config)\n",
    "\n",
    "    # self.bert = RobertaModel(config)\n",
    "    self.bert = BertModel(config)\n",
    "    self.init_weights()\n",
    "      \n",
    "  def forward(self, input_ids, \n",
    "              attention_mask=None, token_type_ids=None): \n",
    "  \n",
    "      outputs = self.bert(input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids #roberta시 주석\n",
    "                          )\n",
    "      \n",
    "      pooled_output = outputs[1]\n",
    "\n",
    "      return pooled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24450,
     "status": "ok",
     "timestamp": 1616574119714,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "wnO1b30SomBP",
    "outputId": "998e38f2-0564-4956-bd43-878798158805"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model on cuda (if available)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3Dgo8U997HD"
   },
   "source": [
    "Train function 정의 후, 두개의 encoder fine-tuning 하기 (In-batch negative 활용) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VAb7NpUc8YRo"
   },
   "outputs": [],
   "source": [
    "def train(args, dataset, p_model, q_model):\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "    {\"params\": [p for n, p in p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "    {\"params\": [p for n, p in p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    {\"params\": [p for n, p in q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "    {\"params\": [p for n, p in q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "  ]\n",
    "\n",
    "  optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=args.learning_rate,\n",
    "    eps=args.adam_epsilon\n",
    "  )\n",
    "  \n",
    "  # Dataloader\n",
    "  train_sampler = RandomSampler(dataset)\n",
    "  train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)\n",
    "\n",
    "# tt\n",
    "  t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "  # Start training!\n",
    "  global_step = 0\n",
    "  \n",
    "  p_model.zero_grad()\n",
    "  q_model.zero_grad()\n",
    "  torch.cuda.empty_cache()\n",
    "  \n",
    "  train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "  for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "      q_encoder.train()\n",
    "      p_encoder.train()\n",
    "      \n",
    "      if torch.cuda.is_available():\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "      p_inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids': batch[2] # roberta시 주석\n",
    "                  }\n",
    "      \n",
    "      q_inputs = {'input_ids': batch[3],\n",
    "                  'attention_mask': batch[4],\n",
    "                  'token_type_ids': batch[5] # roberta시 주석\n",
    "                  }\n",
    "      \n",
    "      p_outputs = p_model(**p_inputs)  # (batch_size, emb_dim)\n",
    "      q_outputs = q_model(**q_inputs)  # (batch_size, emb_dim)\n",
    "\n",
    "\n",
    "      # Calculate similarity score & loss\n",
    "      sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
    "\n",
    "      # target: position of positive samples = diagonal element \n",
    "      targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "      if torch.cuda.is_available():\n",
    "        targets = targets.to('cuda')\n",
    "\n",
    "      sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "      loss = F.nll_loss(sim_scores, targets)\n",
    "      # print(loss)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      q_model.zero_grad()\n",
    "      p_model.zero_grad()\n",
    "      global_step += 1\n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    \n",
    "  return p_model, q_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ICSJoJrUDGZ5"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96513,
     "status": "ok",
     "timestamp": 1616574191784,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "E8a7ww3WgsaZ",
    "outputId": "8f98f6cf-8a44-4e4a-928b-836a1b27a772"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 988/988 [07:30<00:00,  2.19it/s]\n",
      "Iteration: 100%|██████████| 988/988 [07:31<00:00,  2.19it/s]\n",
      "Iteration: 100%|██████████| 988/988 [07:29<00:00,  2.20it/s]\n",
      "Iteration: 100%|██████████| 988/988 [07:31<00:00,  2.19it/s]\n",
      "Iteration: 100%|██████████| 988/988 [07:32<00:00,  2.18it/s]\n",
      "Epoch: 100%|██████████| 5/5 [37:35<00:00, 451.15s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 14051.27it/s]\n"
     ]
    }
   ],
   "source": [
    "p_encoder, q_encoder = tqdm(train(args, train_dataset, p_encoder, q_encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder.save_pretrained('encoders/p_encoder')\n",
    "q_encoder.save_pretrained('encoders/q_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGOw-k7Ln85t"
   },
   "source": [
    "## Dense Embedding을 활용하여 passage retrieval 실습해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96984,
     "status": "ok",
     "timestamp": 1616574192258,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "NouB9uBcTaws",
    "outputId": "f2446b6c-3008-4350-be54-140b194a1a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주이로부터 문흠의 가짜 항복 소식을 들은 인물은?\n",
      "아버지 주환이 고위 관료였기 때문에, 낭(郞)에 서임되었다. 기도위가 되어, 주환의 병사를 대신 거느렸다\\n\\n적오 4년(241년), 오나라에서 병사를 크게 일으켜 위나라를 세 방향으로 치고 들어갔을 때, 주연을 따라 위나라의 번성을 공격했고, 여거와 함께 성의 외곽 방어를 깨트렸다. 주연 군은 사마의의 구원군을 보고 달아나다가 대패했으나, 주이는 이 공적으로 돌아와서는 편장군이 되었다\\n\\n위나라의 여강태수 문흠이 육안에 주둔하면서 수많은 요새를 구축하고, 오나라 사람들에게 모반·망명을 유도하여 오나라에 피해를 입히고 있었다. 주이는 몸소 수하 2천 명을 거느리고 문흠의 일곱 주둔지를 격파하여 수백 급을 베었고, 이 공적으로 양무장군으로 전임했다\\n\\n적오 13년(250년) 10월 , 당시 양주자사인 문흠의 투항 밀사를 받아 친히 문흠을 맞이해 달라는 청을 받았다. 그러나 이것이 거짓 투항임을 간파하고 대제 손권에게 아뢨으며, 손권이 받아들여 여거에게 2만 명을 거느리고 주이를 도와 함께 국경에서 문흠을 기다리게 했다. 문흠은 결국 투항하지 않았다\\n\\n건흥 원년(252년)에는 진남장군으로 전임했다. 이해 12월, 위나라에서 대제가 죽은 틈을 노리고 군사를 크게 일으켜 세 방향으로 오나라를 쳤으며, 제갈탄과 호준이 그 중 한 방향을 맡아 지난달에 오나라의 태부 제갈각이 쌓은 동흥의 두 성을 함몰하고자 했다. 주이는 이 싸움에서 수군을 거느리고 위나라의 부교를 쳐 무너뜨려 위나라 군사를 크게 무찔렀다\\n\\n태평 2년(258년) 6월 , 손침의 명령을 받고 호림(虎林)에서 출발하여 하구독 손일을 암습하려 했는데, 무창에 이르렀을 때 손일이 이를 알아채고 위나라로 달아났다. 7월에 하구에 이르렀다 가절을 받고 전부독(손량전에 따른 것으로, 주환전에서는 대도독)이 되어, 수춘에서 위나라에 반기를 들고 오나라에 도움을 구한 제갈탄을 도와 수춘성의 포위를 풀고자 출진했다. 처음에는 3만 명을 거느리고 안풍성에 주둔하며 이미 성 안으로 들어간 문흠을 후원했으나, 위나라의 연주자사 주태에게 양연(陽淵)에서 저지당해 패퇴했다. 다시 손침의 명령으로 정봉·여비(黎斐) 등과 함께 5만 명을 거느리고 위를 공격하였다. 도륙(都陸)에 치중을 두고, 장군 임도(任度)·장진(張震)에게 용감한 병사 6천을 모아서 부교를 건너 보루를 세우도록 했으나, 감군 석포와 주태의 공격을 받아 깨졌다. 다음에는 공성 무기를 만들어 오목성(五木城)을 쳤으나, 석포·주태에게 또 졌는데다 위나라의 태산태수 호열의 기습을 받아 도륙의 군수 물자가 소실되었다. 주이는 손침에게서 군사 3만을 받아 다시 싸우라는 명령을 받았으나, 식량이 부족해 회군했고, 분노한 대장군 손침에게 9월 초하루에 확리(鑊里)에서 살해당했다 이때 손침은 주이에게 회견을 요청했다. 주이는 두려움을 품은 육항의 반대를 뿌리치고 의심 없이 손침에게 갔으나, 손침이 다짜고짜 주이를 꿇어앉히고 살해했다. 이를 두고 위나라의 사마소는 “주이가 수춘에 이르지 못한 것은 주이의 죄가 아닌데, 오나라에서 죽였다.”라고 했다. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_corpus = list(set([example['context'] for example in dataset['validation']]))#[:10]\n",
    "sample_idx = random.choice(range(len(dataset['validation'])))\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "\n",
    "if not ground_truth in valid_corpus:\n",
    "  valid_corpus.append(ground_truth)\n",
    "\n",
    "print(query)\n",
    "print(ground_truth, '\\n\\n')\n",
    "\n",
    "# valid_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05D8GzFrJhHO"
   },
   "source": [
    "앞서 학습한 passage encoder, question encoder을 이용해 dense embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ba-hH3NQOEWJ"
   },
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "  return tuple(t.cuda() for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97547,
     "status": "ok",
     "timestamp": 1616574192826,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "YufA_ayPJBRg",
    "outputId": "fa600009-393a-4f93-871e-bff93675d05e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([235, 768]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  p_encoder.eval()\n",
    "  q_encoder.eval()\n",
    "\n",
    "  # q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_seqs_val = tokenizer(['해바라기는 무슨 꽃일까?'], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "  p_embs = []\n",
    "  for p in valid_corpus:\n",
    "    p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "    p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "    p_embs.append(p_emb)\n",
    "\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "\n",
    "print(p_embs.size(), q_emb.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOHHak7WS1ko"
   },
   "source": [
    "생성된 embedding에 dot product를 수행 => Document들의 similarity ranking을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97546,
     "status": "ok",
     "timestamp": 1616574192827,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "xn5Cx5JkKZJB",
    "outputId": "eb232f4f-bdae-474d-b630-a13d0b563364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 235])\n",
      "tensor([[232.3053, 238.3758, 238.3100, 239.5861, 237.4889, 234.5634, 237.9858,\n",
      "         232.1852, 239.5936, 236.0988, 239.5917, 226.3246, 235.2983, 237.6539,\n",
      "         236.3513, 229.4015, 231.9859, 234.8343, 236.5229, 236.3486, 238.0967,\n",
      "         232.0994, 235.6399, 233.9610, 236.2306, 232.0301, 235.5572, 226.9109,\n",
      "         239.6329, 233.5367, 231.6475, 232.0976, 235.4974, 234.1947, 232.7057,\n",
      "         235.0099, 239.1635, 239.5350, 229.5685, 238.0921, 242.5622, 244.0243,\n",
      "         239.1308, 237.0562, 236.2374, 242.3420, 238.4786, 236.7240, 235.3503,\n",
      "         242.2222, 236.7791, 239.7298, 236.7359, 235.6611, 239.7487, 233.7325,\n",
      "         241.4185, 232.1245, 236.0488, 232.0436, 238.4375, 233.6498, 229.4159,\n",
      "         235.1036, 233.7758, 236.7264, 244.0305, 236.5325, 232.6063, 231.7659,\n",
      "         237.5415, 238.4850, 220.3715, 229.0396, 231.1714, 233.6785, 219.6081,\n",
      "         229.9293, 226.1010, 232.7872, 233.0021, 237.1839, 238.7932, 236.1073,\n",
      "         238.1964, 233.6539, 235.6383, 233.7250, 236.6259, 234.0049, 238.9952,\n",
      "         237.9997, 236.5690, 234.7501, 231.5589, 237.0534, 231.2358, 228.0027,\n",
      "         238.8546, 233.5006, 236.1921, 229.2211, 233.4327, 242.2980, 238.6877,\n",
      "         234.4955, 237.8724, 239.4998, 233.9361, 233.5848, 236.5268, 236.5746,\n",
      "         235.5220, 234.8423, 232.0876, 236.3732, 249.3571, 242.8874, 234.1411,\n",
      "         232.3703, 232.7851, 239.8425, 236.4625, 229.5610, 238.8723, 236.0614,\n",
      "         236.8555, 234.2770, 237.0626, 233.5513, 233.5188, 232.4633, 231.6671,\n",
      "         231.7120, 232.7615, 228.9335, 231.9791, 235.6370, 234.1566, 236.0933,\n",
      "         226.3166, 236.6490, 236.6269, 238.2075, 232.0209, 237.9961, 240.6099,\n",
      "         241.4114, 240.1393, 234.9273, 241.2373, 232.4259, 233.8310, 239.7376,\n",
      "         237.6649, 235.4408, 239.4337, 235.3737, 236.3576, 234.8388, 237.6433,\n",
      "         234.9173, 236.5164, 227.1196, 229.6265, 230.3758, 236.3654, 237.8683,\n",
      "         237.7089, 240.7515, 231.5086, 241.8031, 234.6113, 236.2108, 236.8846,\n",
      "         239.8003, 237.2189, 237.6664, 236.1657, 236.8671, 230.0720, 236.1908,\n",
      "         231.9062, 233.6097, 239.9534, 233.3092, 238.1406, 235.4054, 231.3413,\n",
      "         236.1322, 239.9230, 240.1776, 229.5848, 238.4035, 230.6990, 235.6986,\n",
      "         239.6307, 236.4466, 236.3467, 239.3706, 233.1323, 229.8434, 245.3709,\n",
      "         228.6778, 235.5593, 237.1543, 231.8646, 232.5938, 239.3361, 237.7663,\n",
      "         229.6968, 227.0362, 239.0864, 231.6425, 241.7213, 238.8622, 231.7033,\n",
      "         241.1328, 237.3563, 233.3024, 230.0786, 232.9743, 232.1824, 229.2840,\n",
      "         229.3463, 232.9820, 239.1255, 245.1733, 232.7874, 238.2610, 238.7505,\n",
      "         235.0503, 242.5656, 240.9832, 234.3079]])\n",
      "tensor([116, 202, 227,  66,  41, 117, 232,  40,  45, 103,  49, 171, 214,  56,\n",
      "        147, 150, 217, 233, 169, 146, 191, 148, 184, 190, 121, 175,  54, 153,\n",
      "         51,  28, 196,   8,  10,   3,  37, 107, 156, 199, 208,  36,  42, 226,\n",
      "        212,  90, 124, 215,  98,  82, 230, 104,  71,  46,  60, 193,   1,   2,\n",
      "        229, 143,  84, 186,  20,  39,  91, 145,   6, 106, 167, 209, 168, 177,\n",
      "        154,  13, 160,  70,   4, 218, 176,  81, 205, 128,  43,  95, 174, 179,\n",
      "        126,  50,  52,  65,  47, 141, 142,  88, 111,  92,  67, 110,  18, 162,\n",
      "        122, 197, 115, 166, 158,  14,  19, 198,  44,  24, 173, 100, 181, 178,\n",
      "        189,  83,   9, 139, 125,  58, 195,  53,  22,  86, 137, 204,  26, 112,\n",
      "         32, 155, 187, 157,  48,  12,  63, 231,  35, 149, 161, 113, 159,  17,\n",
      "         93, 172,   5, 105, 234, 127,  33, 138, 118,  89,  23, 108, 152,  64,\n",
      "         55,  87,  75,  85,  61, 183, 109, 129,  29, 130,  99, 102, 185, 219,\n",
      "        200,  80, 225, 221, 228,  79, 120, 134,  34,  68, 207, 131, 151, 119,\n",
      "          0,   7, 222,  57,  21,  31, 114,  59,  25, 144,  16, 136, 182, 206,\n",
      "         69, 133, 216, 132,  30, 213,  94, 170, 188,  96,  74, 194, 165, 220,\n",
      "        180,  77, 201, 210, 164, 192,  38, 123,  62,  15, 224, 223, 101,  73,\n",
      "        135, 203,  97, 163, 211,  27,  11, 140,  78,  72,  76])\n"
     ]
    }
   ],
   "source": [
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size())\n",
    "\n",
    "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "print(dot_prod_scores)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq2Oiv8MKVS6"
   },
   "source": [
    "Top-5개의 passage를 retrieve 하고 ground truth와 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97544,
     "status": "ok",
     "timestamp": 1616574192827,
     "user": {
      "displayName": "Miyoung Ko",
      "photoUrl": "",
      "userId": "12757166311753740653"
     },
     "user_tz": -540
    },
    "id": "WaStRXYdJ-wI",
    "outputId": "bbf42d40-dfae-49ff-bf12-139452b5849f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 주이로부터 문흠의 가짜 항복 소식을 들은 인물은? \n",
      "\n",
      "[Ground truth passage]\n",
      "아버지 주환이 고위 관료였기 때문에, 낭(郞)에 서임되었다. 기도위가 되어, 주환의 병사를 대신 거느렸다\\n\\n적오 4년(241년), 오나라에서 병사를 크게 일으켜 위나라를 세 방향으로 치고 들어갔을 때, 주연을 따라 위나라의 번성을 공격했고, 여거와 함께 성의 외곽 방어를 깨트렸다. 주연 군은 사마의의 구원군을 보고 달아나다가 대패했으나, 주이는 이 공적으로 돌아와서는 편장군이 되었다\\n\\n위나라의 여강태수 문흠이 육안에 주둔하면서 수많은 요새를 구축하고, 오나라 사람들에게 모반·망명을 유도하여 오나라에 피해를 입히고 있었다. 주이는 몸소 수하 2천 명을 거느리고 문흠의 일곱 주둔지를 격파하여 수백 급을 베었고, 이 공적으로 양무장군으로 전임했다\\n\\n적오 13년(250년) 10월 , 당시 양주자사인 문흠의 투항 밀사를 받아 친히 문흠을 맞이해 달라는 청을 받았다. 그러나 이것이 거짓 투항임을 간파하고 대제 손권에게 아뢨으며, 손권이 받아들여 여거에게 2만 명을 거느리고 주이를 도와 함께 국경에서 문흠을 기다리게 했다. 문흠은 결국 투항하지 않았다\\n\\n건흥 원년(252년)에는 진남장군으로 전임했다. 이해 12월, 위나라에서 대제가 죽은 틈을 노리고 군사를 크게 일으켜 세 방향으로 오나라를 쳤으며, 제갈탄과 호준이 그 중 한 방향을 맡아 지난달에 오나라의 태부 제갈각이 쌓은 동흥의 두 성을 함몰하고자 했다. 주이는 이 싸움에서 수군을 거느리고 위나라의 부교를 쳐 무너뜨려 위나라 군사를 크게 무찔렀다\\n\\n태평 2년(258년) 6월 , 손침의 명령을 받고 호림(虎林)에서 출발하여 하구독 손일을 암습하려 했는데, 무창에 이르렀을 때 손일이 이를 알아채고 위나라로 달아났다. 7월에 하구에 이르렀다 가절을 받고 전부독(손량전에 따른 것으로, 주환전에서는 대도독)이 되어, 수춘에서 위나라에 반기를 들고 오나라에 도움을 구한 제갈탄을 도와 수춘성의 포위를 풀고자 출진했다. 처음에는 3만 명을 거느리고 안풍성에 주둔하며 이미 성 안으로 들어간 문흠을 후원했으나, 위나라의 연주자사 주태에게 양연(陽淵)에서 저지당해 패퇴했다. 다시 손침의 명령으로 정봉·여비(黎斐) 등과 함께 5만 명을 거느리고 위를 공격하였다. 도륙(都陸)에 치중을 두고, 장군 임도(任度)·장진(張震)에게 용감한 병사 6천을 모아서 부교를 건너 보루를 세우도록 했으나, 감군 석포와 주태의 공격을 받아 깨졌다. 다음에는 공성 무기를 만들어 오목성(五木城)을 쳤으나, 석포·주태에게 또 졌는데다 위나라의 태산태수 호열의 기습을 받아 도륙의 군수 물자가 소실되었다. 주이는 손침에게서 군사 3만을 받아 다시 싸우라는 명령을 받았으나, 식량이 부족해 회군했고, 분노한 대장군 손침에게 9월 초하루에 확리(鑊里)에서 살해당했다 이때 손침은 주이에게 회견을 요청했다. 주이는 두려움을 품은 육항의 반대를 뿌리치고 의심 없이 손침에게 갔으나, 손침이 다짜고짜 주이를 꿇어앉히고 살해했다. 이를 두고 위나라의 사마소는 “주이가 수춘에 이르지 못한 것은 주이의 죄가 아닌데, 오나라에서 죽였다.”라고 했다. \n",
      "\n",
      "Top-1 passage with score 249.3571\n",
      "느티나무는 우리나라를 비롯하여 일본, 대만, 중국 등의 따뜻한 지방에 분포하고 있다. 가지가 사방으로 퍼져 자라서 둥근 형태로 보이며, 꽃은 5월에 피고 열매는 원반모양으로 10월에 익는다. 줄기가 굵고 수명이 길어서 쉼터역할을 하는 정자나무로 이용되거나 마을을 보호하고 지켜주는 당산나무로 보호를 받아왔다. \\n\\n합천 성산리의 느티나무는 1그루로, 높이 25m, 둘레 6m 10㎝이며, 나이가 약 500년 정도로 추정된다. 주위에는 이 나무보다 크기가 작고 나이가 적은 느티나무 4그루가 함께 정자나무 숲을 이루고 있으며, 이 나무들 중앙에는 이 나무와 같은 크기였을 것으로 보이는 느티나무 한 그루가 죽어서 그루터기만 남아 있고 옆에는 썩다 남은 줄기 일부가 제자리에 잘 보존되어 있다.\\n\\n이들 느티나무 남쪽에 있는 황강 제방은 강물의 범람과 느티나무들의 보호를 위하여 현재 4m 높이의 콘크리트 옹벽이 30m 정도 처져 있다. 이곳은 옛날부터 최근까지 합천 북부지방 사람들이 항강을 배로 건너서 남쪽의 초계 지방을 오가는 큰 나루터였던 곳이나 황강다리가 놓여진 지금 이 나루터에는 옛날의 북적거리는 모습은 간데 없고 느티나무들만 한가로이 서 있다.\\n\\n나무의 흉고 둘레가 6m 이상이 되며 수령이 500여년이나 되는 거대한 고목인 동시에 이 지역 사람들이 이 곳을 신성시하고 있고 나무에 얽힌 유래와 전설 등을 고려할 때 문화재적 가치가 있다.\n",
      "Top-2 passage with score 245.3709\n",
      "수를 놓을 때에 사용하는 기법을 문양의 형태에 따라 나누어 보면 선을 잇는 수, 면을 메우는 수, 어떤 무늬를 나타내는 수로 나눌 수 있다. 그 종류로는 아주 작은 점으로 표현되는 점수를 비롯해서 선을 표현하는 이음수, 실을 간격이 없이 고루 펴는 평수, 양쪽으로 갈라져 있는 잎을 수놓는 가름수, 수평으로 나란히 수놓는 푼사수, 서양 자수의 코칭 스티치와 같은 수법으로 노끈·굵은 실·금사·은사 같은 다른 가는 실로 징그어 주는 기법인 징금수, 색의 자연스러운 변화를 표현하는 데 이용되는 자련수, 돗자리의 겉모양을 표현하는 기법인 자릿수, 겉수의 입체감을 나타내기 위해 양감(量感)을 표현하는 속수, 일정하게 간격을 띄우고 수평으로 수놓는 기법인 관수, 양지관수로 밑수를 수놓은 다음 밑수의 색과 유사한 색으로 실과 실사이를 어슷하게 건너주는 엇겨놓기수, 새의 깃털을 표현하는 새털수, 결의 방향을 규칙적으로 바꾸어 가며 무늬를 만드는 무늬목수, 삼나무 잎모양처럼 엮어나간 연속무늬의 기법인 삼잎수, 소나무 잎을 수놓을 때 쓰는 솔잎수, 별모양처럼 표현하는 별무늬수, 금·은사를 사용하여 평사수로 밑수한 위에 징금수하여 기하학적인 문양을 만드는 칠보수 등이 있다.\n",
      "Top-3 passage with score 245.1733\n",
      "오스트레일리아에서 발견된 것 중 가장 온전하고 풍부한 아우스트랄로할키에리아 수페르스테스의 학명은 \"남쪽에서 살아남은 할키에리아\"라는 의미를 가지고 있는데, 이것은 해당 종이 보토마절 말의 멸종사건에서 살아남은 할키에리아류이기 때문이다. 이 종으로 분류된 골편은 위쪽 표면으로는 볼록하고 아래쪽은 오목하다. 또 골편이 있는 평면 상에서 휘어 있으며 서로 겹쳐져 있는데, 각각의 골편에서 오목한 부분은 다음 골편의 볼록한 부분에 덮여 있다. 아우스트랄로할키에리아 내부의 빈 공간은 할키에리아의 단순한 관 모양보다 더 복잡한 형태를 가지는데 골편 높이의 절반 정도를 올라가면 원통 모양의 관이 한 쌍의 가느다란 관으로 나뉘고, 가운데 부분은 납작해 져서 양쪽의 관은 연결되어 있지 않은 것으로 보인다. 골편의 측면 역시 다른 미세구조를 가지고 있다\\n\\nA. 수페르스테스의 골편 중앙 관의 위쪽은 납작한 형태로 표면 바로 밑에 위치하는데 이때문에 위쪽 표면의 끝쪽에는 움푹 들어간 자국이 생긴다. 이 부분은 광물화되지 않은 상태로 남아 있어서 이것이 물 속의 화학물질을 받아들여 후각의 역할을 했을 수도 있다. A. 수페르스테스 골편이 인산염성분으로 덮여 있는 것은 원래 유기질 피부로 덮여 있었기 때문일 가능성이 있다. 선인장처럼 생긴 챈슬로리드(chancelloriid)의 골편 역시 유기질로 덮여 있는 경우가 있다. 만일 할키에리아류가 초기 연체동물이었다면 골편의 표면은 현생 연체동물 일부에서 볼 수 있는 각피층과 유사했을지도 모른다\\n\\nA. 수페르스테스의 골편은 서로 거울상을 하고 있는 두 종류로 이루어지는데, 이 두 종류 골편이 발견되는 양이 비슷한 것으로 보아 A. 수페르스테스는 좌우대칭의 몸을 가지고 있었던 것으로 보인다. 골편은 모두 매우 작은 크기로, 손바닥형은 250 µm 에서 650 µm, 칼날형은 300 µm 에서 1000 µm 정도의 길이를 가진다. 낫형은 다시 두 그룹으로 나뉘는데 밑부분에 완만한 S-곡선을 가지고 있는 것은 400 µm 에서 1000µm의 길이로 바닥쪽이 살짝 비틀려 있는 경우가 많으며, 밑부분이 45° 에서 90° 휘어져 있는 것은 400 µm 에서 500 µm 정도 길이이다\\n\\n초기 캄브리아기 할키에리아류의 골편체에는 낫형 골편보다 손바닥형 및 칼날형 골편이 훨씬 더 많이 포함되어 있다. 반면, A. 수페르스테스의 낫\\n형 골편은 칼날형이나 손바닥형보다 훨씬 더 많이 발견되며 손바닥형 골편은 드물다. 어쩌면 사망 이후 어떤 과정에 의해 다수의 손바닥형과 일부 칼날형 골편이 제거되었을 수도 있지만, A. 수페르스테스의 골편체 중 해저 가까이에 있는 바닥 부분이 상대적으로 측면이나 위쪽 부분보다 더 큰 면적을 차지하고 있었을 가능성이 높다. 또 A. 수페르스테스 골편은 초기 캄브리아기 할키에리아류의 골편에 비해 1/3 정도 크기밖에 되지 않는다. 대부분의 초기 캄브리아기 할키에리아류와 더 큰 생물들을 포함하는 조지나 어셈블리지의 화석들이 모두 동일한 방식, 즉 인산염화가 일어나는 방식으로 보존되었기 때문에 보존 방식에서의 차이가 이런 차이를 만들어냈을 가능성은 적다. A. 수페르스테스의 크기가 작은 이유에 대한 설명으로는 조지나 어셈블리지의 할키에리아류가 어린 것이었을 가능성, 이들의 골편체가 초기 캄브리아기 할키에리아류보다 더 많은 수의 골편들로 구성되어 있었을 가능성, 혹은 A. 수페르스테스의 크기가 원래 작았을 가능성 등이 꼽힌다\\n\\n조지나 분지에서는 할키에리아류의 껍질로 분류될 수 있는 화석이 발견되지 않았다. 할키에리아의 껍질도 매우 드물게 발견되기 때문에 이것이 아우스트랄로할키에리아가 껍질을 가지고 있지 않았다는 의미는 아니다\n",
      "Top-4 passage with score 244.0305\n",
      "기묘한 정적이 감도는 한 마을에 마리아치 가수 엘 마리아치(El Mariachi: 카를로스 기아르도 분)와 악당 아주르(Azul: 레이놀 마티네즈 분)가 나타난다. 그들은 공교롭게도 둘다 검은 옷을 입고 검은 기타 케이스를 들고 있다. 그러나 엘마리아치의 기타 케이스 안에는 그가 가장 아끼는 기타가 들어 있고 악당 아주르의 케이스 안에는 무기로 채워져 있다. 악당 아주르는 그 지역 폭력 조직의 두목 모코(Mauricio (Moco): 피터 마르쿠아드트 분)의 부하였으나 그에게 배반당하고 자신을 죽이기 위해 감옥으로 부하들을 보낸 모코에게 복수하고 자기의 몫을 찾기위해 마을에 들어 온다. 한편 기타 하나를 들고 마리아치를 부르며 방랑 생활을 하는 엘 마리아치는 마을에 들어와 노래할 곳을 찾아 다닌다. 모코와 아주르 사이에서 마리아치는 아주르로 오해를 받으며 노래할 곳을 찾았는데 바로 그곳의 여 주인도 모코의 여자로 이 또한 곤경의 여지를 만든다. 우여곡절 끝에 악당들을 모두 처치하고 마리아치는 또다시 정처없이 떠난다.\n",
      "Top-5 passage with score 244.0243\n",
      "연구가 많이 되지 않았기에 아직까지 조류의 성체는 매우 제한된 재생능력을 가진 것으로 알려져있다. 수탉에 관한 일부 연구들은 새들이 적절하게 수족의 일부를 재생할 수 있다고 제안되었고, 동물의 나이, 손상 조직과 다른 근육 간의 상호 관계, 재생 작동의 종류와 같이 재생이 일어나는 조건에 따라서 어떤 근육 골격 구조들의 완전 재생이 수반될 수 있다고 제안한다. 웨버와 골드스미스(1909)는 거위와 오리는 부리가 일부 잘렸을 때 재생되는 것을 발견했, 시도로바(1962)는 수탉의 간비대를 통해서 간 재생을 관찰했다. 새는 소음 손상과 이독성 약을 통한 손상에 따라서 그들의 달팽이관에 있는 털세포를 재생할 수 있다. 이런 증거들에도 불구하고 최근의 연구들은 새들에서의 반복적인 재생이 배아 발생 시기에 국한되어 있다고 제안한다. 여러 분자생물학기술로 세포 경로를 조작하여 닭의 배아에서 성공적으로 자발적인 재생이 일어나도록 만들었다. 예를 들어 창 절제술이나 절편 절제술을 이용해 닭 배아의 팔꿈치 관절의 일부를 제거하는 것과 관절 조직 특이 마커들과 연골 마커들을 비교하는 것을 통해, 창 절제술은 20 개 중 10 개에서 수족 재생과 발생에서 나오는 것과 유사한 관절 유전자를 발현하는 것을 보였다. 반면에 절편 절제술은 연골 마커의 발현으로 유도되는 골격 요소의 융합 때문에 관절의 재생을 유도하지 못했다. \\n\\n포유류에서 보이는 털의 생리학적 재생과 유사하게 새들은 손상된 깃털을 수리하거나 깃털을 이용해 짝을 매혹하기 위해서 깃털을 재생할 수 있다. 일반적으로 번식기와 연관되어 있는 계절의 변화는 새의 깃털 재생을 시작하게 하는 호르몬 신호로 자극된다. 이는 실험적으로 로드아일랜드닭에서 갑상선 호르몬을 이용해 유도되었다.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "print(\"[Search query]\\n\", query, \"\\n\")\n",
    "print(\"[Ground truth passage]\")\n",
    "print(ground_truth, \"\\n\")\n",
    "\n",
    "for i in range(k):\n",
    "  print(\"Top-%d passage with score %.4f\" % (i+1, dot_prod_scores.squeeze()[rank[i]]))\n",
    "  print(valid_corpus[rank[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBaKYpdoXDcW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MRC Practice 5 - Dense Passage Retrieval (In-batch)",
   "provenance": [
    {
     "file_id": "1c9Vr7z_LBG2l9K4lVb40pu7Kk22hXQCp",
     "timestamp": 1614240569955
    },
    {
     "file_id": "1Q7iAXm_kwF_NHfOEGdViMCiPHnqoZlXe",
     "timestamp": 1613491158162
    }
   ]
  },
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
