{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets==1.13.3 -q\n",
    "# !pip install transformers==4.11.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    "    RobertaModel, RobertaPreTrainedModel\n",
    "\n",
    ")\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRetrieval:\n",
    "  def __init__(self, args, dataset, num_neg, tokenizer, p_encoder, q_encoder):\n",
    "\n",
    "    self.args = args\n",
    "    self.dataset = dataset\n",
    "    self.num_neg = num_neg\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.p_encoder = p_encoder\n",
    "    self.q_encoder = q_encoder\n",
    "\n",
    "    self.prepare_in_batch_negative(num_neg=num_neg)\n",
    "\n",
    "  def prepare_in_batch_negative(self, dataset=None, num_neg=2, tokenizer=None):\n",
    "    if dataset is None:\n",
    "      dataset = self.dataset\n",
    "    \n",
    "    if tokenizer is None:\n",
    "      tokenizer = self.tokenizer\n",
    "    \n",
    "    corpus = np.array(list(set([example for example in dataset['context']])))\n",
    "    p_with_neg = []\n",
    "\n",
    "    for c in dataset['context']:\n",
    "      while True:\n",
    "        neg_idxs = np.random.randint(len(corpus), size=num_neg)\n",
    "\n",
    "        if c not in corpus[neg_idxs]:\n",
    "          p_neg = corpus[neg_idxs]\n",
    "\n",
    "          p_with_neg.append(c)\n",
    "          p_with_neg.extend(p_neg)\n",
    "          break\n",
    "\n",
    "    q_seqs = tokenizer(\n",
    "      dataset['question'],\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_tensors = 'pt',\n",
    "      return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "    p_seqs = tokenizer(\n",
    "      p_with_neg,\n",
    "      padding = 'max_length',\n",
    "      truncation=True,\n",
    "      return_tensors = 'pt',\n",
    "      return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "    max_len = p_seqs['input_ids'].size(-1)\n",
    "    p_seqs['input_ids'] = p_seqs['input_ids'].view(-1, num_neg+1, max_len)\n",
    "    p_seqs['attention_mask'] = p_seqs['attention_mask'].view(-1, num_neg+1, max_len)\n",
    "    print(len(p_with_neg))\n",
    "    print(p_seqs['input_ids'].shape)\n",
    "    print(p_seqs['attention_mask'].shape)\n",
    "    print(q_seqs['input_ids'].shape)\n",
    "    print(q_seqs['attention_mask'].shape)\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "      p_seqs['input_ids'], p_seqs['attention_mask'],\n",
    "      q_seqs['input_ids'], q_seqs['attention_mask']\n",
    "    )\n",
    "\n",
    "    self.train_dataloader = DataLoader(\n",
    "      train_dataset,\n",
    "      shuffle=True,\n",
    "      batch_size = self.args.per_device_train_batch_size\n",
    "    )\n",
    "\n",
    "    valid_seqs = tokenizer(\n",
    "      dataset['context'],\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    passage_dataset = TensorDataset(\n",
    "      valid_seqs['input_ids'],\n",
    "      valid_seqs['attention_mask']\n",
    "    )\n",
    "\n",
    "    self.passage_dataloader = DataLoader(\n",
    "      passage_dataset,\n",
    "      batch_size = self.args.per_device_train_batch_size\n",
    "    )\n",
    "\n",
    "  def train(self, args=None):\n",
    "    if args is None:\n",
    "      args = self.args\n",
    "    batch_size = args.per_device_train_batch_size\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "      {\"params\": [p for n, p in self.p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "      {\"params\": [p for n, p in self.p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "      {\"params\": [p for n, p in self.q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "      {\"params\": [p for n, p in self.q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(\n",
    "      optimizer_grouped_parameters,\n",
    "      lr=args.learning_rate,\n",
    "      eps=args.adam_epsilon\n",
    "    )\n",
    "    t_total = len(self.train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps = args.warmup_steps,\n",
    "      num_training_steps = t_total\n",
    "    )\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    self.p_encoder.zero_grad()\n",
    "    self.q_encoder.zero_grad()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_iterator = tqdm(range(int(args.num_train_epochs)), desc='Epoch')\n",
    "\n",
    "    for _ in train_iterator:\n",
    "\n",
    "      with tqdm(self.train_dataloader, unit='batch') as tepoch:\n",
    "        for batch in tepoch:\n",
    "          self.p_encoder.train()\n",
    "          self.q_encoder.train()\n",
    "\n",
    "          targets = torch.zeros(batch_size).long()\n",
    "          targets = targets.to(args.device)\n",
    "\n",
    "          p_inputs = {\n",
    "            \"input_ids\": batch[0].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "            \"attention_mask\": batch[1].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "          }\n",
    "\n",
    "          q_inputs = {\n",
    "            \"input_ids\": batch[2].to(args.device),\n",
    "            \"attention_mask\": batch[3].to(args.device),\n",
    "          }\n",
    "\n",
    "          p_outputs = self.p_encoder(**p_inputs)\n",
    "          q_outputs = self.q_encoder(**q_inputs)\n",
    "\n",
    "          p_outputs = p_outputs.view(batch_size, -1, self.num_neg+1)\n",
    "          q_outputs = q_outputs.view(batch_size, 1, -1)\n",
    "\n",
    "          sim_scores = torch.bmm(q_outputs, p_outputs).squeeze()\n",
    "          sim_scores = sim_scores.view(batch_size, -1)\n",
    "          sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "          loss = F.nll_loss(sim_scores, targets)\n",
    "          tepoch.set_postfix(loss=f'{str(loss.item())}')\n",
    "\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          scheduler.step()\n",
    "\n",
    "          self.p_encoder.zero_grad()\n",
    "          self.q_encoder.zero_grad()\n",
    "\n",
    "          global_step += 1\n",
    "\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "          del p_inputs, q_inputs\n",
    "\n",
    "        print('loss:', loss)\n",
    "        print('sim_scores:', sim_scores)\n",
    "        print('targets:', targets)\n",
    "        print('p_outputs:', p_outputs)\n",
    "        print('q_outputs:', q_outputs)\n",
    "\n",
    "  def get_relevant_doc(self, query, k=1, args=None, p_encoder=None, q_encoder=None):\n",
    "    if args is None:\n",
    "      args = self.args\n",
    "    \n",
    "    if p_encoder is None:\n",
    "      p_encoder = self.p_encoder\n",
    "    \n",
    "    if q_encoder is None:\n",
    "      q_encoder = self.q_encoder\n",
    "\n",
    "    with torch.no_grad():\n",
    "      p_encoder.eval()\n",
    "      q_encoder.eval()\n",
    "\n",
    "      q_seqs_val = self.tokenizer(\n",
    "        [query],\n",
    "        padding = 'max_length',\n",
    "        truncation= True,\n",
    "        return_tensors = 'pt',\n",
    "        return_token_type_ids=False,\n",
    "      ).to(args.device)\n",
    "      q_emb = q_encoder(**q_seqs_val).to('cpu')\n",
    "\n",
    "      p_embs = []\n",
    "      for batch in self.passage_dataloader:\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        p_inputs = {\n",
    "          'input_ids': batch[0],\n",
    "          'attention_mask': batch[1]\n",
    "        }\n",
    "        p_emb = p_encoder(**p_inputs).to('cpu')\n",
    "        p_embs.append(p_emb)\n",
    "    \n",
    "    p_embs = torch.stack(\n",
    "      p_embs, dim = 0\n",
    "    ).view(len(self.passage_dataloader.dataset), -1)\n",
    "\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "\n",
    "    return rank[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaEncoder(RobertaPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "\n",
    "    self.roberta = RobertaModel(config)\n",
    "    self.init_weights()\n",
    "\n",
    "  def forward(self, input_ids, attention_mask=None):\n",
    "    outputs = self.roberta(\n",
    "      input_ids,\n",
    "      attention_mask = attention_mask\n",
    "    )\n",
    "\n",
    "    pooled_output = outputs[1]\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaEncoder: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaEncoder were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaEncoder: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaEncoder were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_from_disk('../data/train_dataset')['train']\n",
    "\n",
    "# num_sample = 1500\n",
    "sample_idx = np.random.choice(range(len(train_dataset)),100)# len(train_dataset))#num_sample)\n",
    "train_dataset = train_dataset[sample_idx]\n",
    "\n",
    "args = TrainingArguments(\n",
    "  output_dir = 'dense_retrieval',\n",
    "  evaluation_strategy = 'epoch',\n",
    "  learning_rate=3e-4,\n",
    "  per_device_train_batch_size=4,\n",
    "  per_device_eval_batch_size=4,\n",
    "  num_train_epochs=20,\n",
    "  weight_decay=0.01\n",
    ")\n",
    "\n",
    "model_checkpoint = 'klue/roberta-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "p_encoder = RobertaEncoder.from_pretrained(model_checkpoint).to(args.device)\n",
    "q_encoder = RobertaEncoder.from_pretrained(model_checkpoint).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "torch.Size([100, 3, 512])\n",
      "torch.Size([100, 3, 512])\n",
      "torch.Size([100, 512])\n",
      "torch.Size([100, 512])\n"
     ]
    }
   ],
   "source": [
    "retriever = DenseRetrieval(\n",
    "  args=args,\n",
    "  dataset=train_dataset,\n",
    "  num_neg=2,\n",
    "  tokenizer=tokenizer,\n",
    "  p_encoder=p_encoder,\n",
    "  q_encoder=q_encoder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16c7261b13e4ca2a02920c0263bfc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa76136e29b4fe5a61547482a99eea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sim_scores: tensor([[  0.0000, -36.2715, -33.5280],\n",
      "        [  0.0000, -33.6338, -30.8933],\n",
      "        [  0.0000, -32.9475, -33.4464],\n",
      "        [  0.0000, -35.5509, -33.0377]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
      "p_outputs: tensor([[[ 0.7665, -0.3564, -0.3816],\n",
      "         [-0.0367,  0.2894,  0.3136],\n",
      "         [ 0.6012, -0.3007, -0.3840],\n",
      "         ...,\n",
      "         [ 0.4860, -0.2657, -0.4362],\n",
      "         [ 0.3290,  0.1557, -0.0745],\n",
      "         [ 0.0975,  0.3837, -0.0794]],\n",
      "\n",
      "        [[ 0.7777, -0.3719, -0.3677],\n",
      "         [-0.0216,  0.3977,  0.2892],\n",
      "         [ 0.6853, -0.2343, -0.4033],\n",
      "         ...,\n",
      "         [ 0.5859, -0.3296, -0.4845],\n",
      "         [ 0.1809,  0.1992, -0.0325],\n",
      "         [ 0.1128,  0.3624, -0.0491]],\n",
      "\n",
      "        [[ 0.7480, -0.1989, -0.1939],\n",
      "         [-0.0035,  0.4077,  0.2799],\n",
      "         [ 0.7513, -0.2256, -0.4738],\n",
      "         ...,\n",
      "         [ 0.4463, -0.2737, -0.4403],\n",
      "         [ 0.1733,  0.1981, -0.2549],\n",
      "         [ 0.1448,  0.4337, -0.1258]],\n",
      "\n",
      "        [[ 0.7942, -0.2409, -0.2310],\n",
      "         [-0.0472,  0.4539,  0.2727],\n",
      "         [ 0.6632, -0.2526, -0.3187],\n",
      "         ...,\n",
      "         [ 0.5708, -0.3974, -0.5459],\n",
      "         [ 0.2714,  0.1115, -0.1355],\n",
      "         [ 0.1019,  0.4077, -0.1463]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "q_outputs: tensor([[[ 0.7195, -0.2071,  0.4960,  ..., -0.3245,  0.3830, -0.0918]],\n",
      "\n",
      "        [[ 0.7629, -0.2980,  0.4565,  ..., -0.3825,  0.2719, -0.0902]],\n",
      "\n",
      "        [[ 0.6334, -0.2593,  0.6034,  ..., -0.1982,  0.3520, -0.1106]],\n",
      "\n",
      "        [[ 0.6400, -0.2589,  0.5819,  ..., -0.3636,  0.4537,  0.0105]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d647688779844326a3710f8e93e88c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sim_scores: tensor([[  0.0000, -33.9484, -32.3214],\n",
      "        [  0.0000, -37.2396, -35.1630],\n",
      "        [  0.0000, -36.4343, -34.8406],\n",
      "        [  0.0000, -37.7212, -33.5250]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
      "p_outputs: tensor([[[ 0.7283, -0.2782, -0.3960],\n",
      "         [-0.1723,  0.3850,  0.3093],\n",
      "         [ 0.7240, -0.3547, -0.4093],\n",
      "         ...,\n",
      "         [ 0.4994, -0.2296, -0.4526],\n",
      "         [ 0.2878,  0.0827, -0.1738],\n",
      "         [ 0.0856,  0.3798, -0.1744]],\n",
      "\n",
      "        [[ 0.7771, -0.2875, -0.3463],\n",
      "         [ 0.0338,  0.3397,  0.2189],\n",
      "         [ 0.6516, -0.3365, -0.4305],\n",
      "         ...,\n",
      "         [ 0.5655, -0.3576, -0.3055],\n",
      "         [ 0.3177,  0.2295, -0.2541],\n",
      "         [ 0.1171,  0.3897, -0.0474]],\n",
      "\n",
      "        [[ 0.7955, -0.1573, -0.3373],\n",
      "         [-0.0280,  0.5440,  0.1915],\n",
      "         [ 0.7047, -0.2997, -0.3354],\n",
      "         ...,\n",
      "         [ 0.5413, -0.2755, -0.5031],\n",
      "         [ 0.2522,  0.2390, -0.1516],\n",
      "         [ 0.1558,  0.4381, -0.0943]],\n",
      "\n",
      "        [[ 0.7266, -0.3340, -0.3105],\n",
      "         [-0.1832,  0.3621,  0.1085],\n",
      "         [ 0.7398, -0.4168, -0.3827],\n",
      "         ...,\n",
      "         [ 0.4485, -0.3861, -0.4428],\n",
      "         [ 0.2789,  0.1865, -0.1877],\n",
      "         [ 0.0169,  0.4488, -0.1087]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "q_outputs: tensor([[[ 0.6588, -0.2702,  0.6232,  ..., -0.3208,  0.4245,  0.0305]],\n",
      "\n",
      "        [[ 0.7442, -0.1962,  0.5956,  ..., -0.3066,  0.2750, -0.0532]],\n",
      "\n",
      "        [[ 0.7576, -0.3115,  0.5508,  ..., -0.3198,  0.2723,  0.0379]],\n",
      "\n",
      "        [[ 0.7152, -0.0888,  0.5491,  ..., -0.3946,  0.3449,  0.0866]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fae5b75e9c4c9ea528ab6d6337dfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sim_scores: tensor([[  0.0000, -36.1319, -34.3498],\n",
      "        [  0.0000, -36.6715, -34.1869],\n",
      "        [  0.0000, -35.6580, -33.2139],\n",
      "        [  0.0000, -36.9912, -33.9816]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
      "p_outputs: tensor([[[ 0.7786, -0.1885, -0.3027],\n",
      "         [-0.1171,  0.3619,  0.2814],\n",
      "         [ 0.6890, -0.2983, -0.4287],\n",
      "         ...,\n",
      "         [ 0.5079, -0.3488, -0.4871],\n",
      "         [ 0.2321,  0.1499, -0.1742],\n",
      "         [ 0.1187,  0.4083, -0.0246]],\n",
      "\n",
      "        [[ 0.7824, -0.3777, -0.3374],\n",
      "         [-0.1218,  0.3723,  0.2376],\n",
      "         [ 0.6819, -0.3006, -0.3569],\n",
      "         ...,\n",
      "         [ 0.4983, -0.2839, -0.4383],\n",
      "         [ 0.2174,  0.2396, -0.0073],\n",
      "         [ 0.0654,  0.4904, -0.1698]],\n",
      "\n",
      "        [[ 0.6927, -0.1552, -0.3062],\n",
      "         [-0.1664,  0.1812,  0.2645],\n",
      "         [ 0.6922, -0.3630, -0.3428],\n",
      "         ...,\n",
      "         [ 0.5324, -0.3162, -0.4934],\n",
      "         [ 0.2515,  0.2066, -0.2184],\n",
      "         [ 0.0983,  0.3677, -0.1403]],\n",
      "\n",
      "        [[ 0.7789, -0.3003, -0.2946],\n",
      "         [-0.1721,  0.4513,  0.3191],\n",
      "         [ 0.7413, -0.2701, -0.4390],\n",
      "         ...,\n",
      "         [ 0.4502, -0.3493, -0.3518],\n",
      "         [ 0.2043,  0.1090, -0.0551],\n",
      "         [ 0.0547,  0.3671, -0.1520]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "q_outputs: tensor([[[ 0.7403, -0.0689,  0.4210,  ..., -0.3613,  0.4739, -0.0573]],\n",
      "\n",
      "        [[ 0.7272, -0.1710,  0.5550,  ..., -0.3373,  0.4341,  0.0423]],\n",
      "\n",
      "        [[ 0.6956, -0.1900,  0.5548,  ..., -0.3439,  0.3652, -0.1124]],\n",
      "\n",
      "        [[ 0.7408, -0.3303,  0.5421,  ..., -0.3623,  0.3373, -0.0477]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f0243792de403592ac59dcf097c80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23758/1239205259.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23758/1490948575.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    152\u001b[0m           \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{str(loss.item())}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_hook_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m def grad(\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_TensorOrTensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_TensorOrTensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"해바라기는 무슨꽃일까?\"\n",
    "results = retriever.get_relevant_doc(query=query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search Query] 해바라기는 무슨꽃일까?\n",
      "\n",
      "Top-1th Passage (Index 1037)\n",
      "('소비에트 연방은 미하일 고르바초프가 집권하고 난 뒤 대대적인 변화를 맞게 되었다. 우선 정부에 대한 비판을 허가하였으며, 페레스트로이카를 '\n",
      " '표방, 미국과의 지속적인 대화를 통해 해빙 조짐을 서서히 보이기 시작하게 되었다. 이 와중에서 고르바초프는 미국의 레이건 대통령과 만나 '\n",
      " '핵무기를 대폭 감축하는 데 합의하게 된다. 그리고 소련은 반세기 동안 적국이었던 대한민국과 1990년에 수교했다.\\\\n\\\\n한편, 침체된 '\n",
      " '자국의 경제를 중흥시키기 위해 소련은 공산주의 종주국으로서의 자리를 포기한다고 선언했고 이는 중앙유럽 공산 국가들의 급속한 붕괴를 '\n",
      " '불러왔다.\\\\n그러나 이러한 고르바초프의 행동에 대해 두려움을 느꼈던 소련의 공산당(볼셰비키)과 국가보안위원회(KGB) 그리고 군과 '\n",
      " '군산복합체는 쿠데타를 일으켜 고르바초프를 권좌에서 몰아내려고 하였으나, 소련 국민들의 거센 반대에 부딪히면서 실패하였다.\\\\n\\\\n쿠데타 '\n",
      " '저지 후, 옐친과 고르바초프는 소련의 미래에 대한 의견을 주고받았다. 옐친은 소련을 해체시키고, 새로운 독립국가들끼리의 연합을 구성하자고 '\n",
      " '제안하였으나, 고르바초프는 중앙정부의 힘을 최소화하는 것을 전제로 하여 소련을 존속시키자는 의견으로 맞섰다.\\\\n\\\\n한동안 양측은 의견 '\n",
      " '차이를 두고 팽팽하게 대립하였으나, 결국 옐친의 뜻대로 되어 고르바초프는 1991년 크리스마스에 대통령 자리에서 물러나게 되었고, '\n",
      " '70년간 세계를 호령하던 소비에트 연방은 붕괴되었고 12개 독립 국가로 구성된 독립 국가 연합(CIS)이 탄생하였다.')\n",
      "Top-2th Passage (Index 1339)\n",
      "('소비에트 연방은 미하일 고르바초프가 집권하고 난 뒤 대대적인 변화를 맞게 되었다. 우선 정부에 대한 비판을 허가하였으며, 페레스트로이카를 '\n",
      " '표방, 미국과의 지속적인 대화를 통해 해빙 조짐을 서서히 보이기 시작하게 되었다. 이 와중에서 고르바초프는 미국의 레이건 대통령과 만나 '\n",
      " '핵무기를 대폭 감축하는 데 합의하게 된다. 그리고 소련은 반세기 동안 적국이었던 대한민국과 1990년에 수교했다.\\\\n\\\\n한편, 침체된 '\n",
      " '자국의 경제를 중흥시키기 위해 소련은 공산주의 종주국으로서의 자리를 포기한다고 선언했고 이는 중앙유럽 공산 국가들의 급속한 붕괴를 '\n",
      " '불러왔다.\\\\n그러나 이러한 고르바초프의 행동에 대해 두려움을 느꼈던 소련의 공산당(볼셰비키)과 국가보안위원회(KGB) 그리고 군과 '\n",
      " '군산복합체는 쿠데타를 일으켜 고르바초프를 권좌에서 몰아내려고 하였으나, 소련 국민들의 거센 반대에 부딪히면서 실패하였다.\\\\n\\\\n쿠데타 '\n",
      " '저지 후, 옐친과 고르바초프는 소련의 미래에 대한 의견을 주고받았다. 옐친은 소련을 해체시키고, 새로운 독립국가들끼리의 연합을 구성하자고 '\n",
      " '제안하였으나, 고르바초프는 중앙정부의 힘을 최소화하는 것을 전제로 하여 소련을 존속시키자는 의견으로 맞섰다.\\\\n\\\\n한동안 양측은 의견 '\n",
      " '차이를 두고 팽팽하게 대립하였으나, 결국 옐친의 뜻대로 되어 고르바초프는 1991년 크리스마스에 대통령 자리에서 물러나게 되었고, '\n",
      " '70년간 세계를 호령하던 소비에트 연방은 붕괴되었고 12개 독립 국가로 구성된 독립 국가 연합(CIS)이 탄생하였다.')\n",
      "Top-3th Passage (Index 91)\n",
      "('1941년 6월, 독일이 소련과 체결한 독일-소련 불가침 조약을 일방적으로 파기하고 소련을 침공하면서 예방조치로, 또한 랜드리스 물자를 '\n",
      " '전달하기 위한 보급로로 사용하기 위한 목적으로 1941년 8월 25일 영국과 소련은 합동으로 이란을 침공하였다 이 때문에 레자 샤 '\n",
      " '팔라비는 퇴위되어 모리셔스로 망명하였으며, 그의 아들 모하마드 레자 팔라비 왕세자가 이란의 새 군주가 되었다. 1942년 1월에는 영소이 '\n",
      " '\"삼자 조약\"을 통하여 현 군 주둔은 점령의 목적이 아니며, 이란은 연합국의 일원이고 종전 6개월 내에 이란 영토에서 철수하겠다고 '\n",
      " '합의했다\\\\n\\\\n전쟁 기간 내내 영미는 이란을 나치 독일과 맞서 싸우는 소련에 군수 물자를 제공하는 중요한 보급로 역할로 이용했다. '\n",
      " '3만명에 달하는 미군 비전투 요원과 보급물자가 이란을 거쳐갔으며, 나중에는 \"승리의 다리\"라는 말이 붙여지기도 했다. 1943년 테헤란 '\n",
      " '회담에서는 영미소 빅3가 이란의 미래 주권과 영토 보전을 보장해주었으며 전후 재건과 개발을 위한 자금 지원도 약속했다. \\\\n\\\\n이란의 '\n",
      " '점령은 독일 항복 이후 열린 포츠담 회담에서 전후 끝난다고 말했지만, 소련의 이오시프 스탈린은 앞서 테헤란 회담에서 합의한 처칠의 연합국 '\n",
      " '철수안에 대해 반대했다. 하지만 소련군은 합의 기한인 3월 2일을 넘겨도 철수하지 않았으며 오히려 군사를 남쪽으로 진격시켰다. 1945년 '\n",
      " '12월 말 군대와 비밀경찰을 동원하여 이란 영토 내에 친소 \"인민공화국\" 자파르 피셰바리의 아제르바이잔 인민 정부와 카지 무함마드의 '\n",
      " '마하바드 공화국을 독립시켰다.\\\\n\\\\n1945년 9월, 이란 길란 주의 오랜 기간 혁명 운동의 지도자 노릇을 하던 자파르 피셰바리는 '\n",
      " '아제르바이잔인 민주당(ADP)를 창당한다. 이 당은 이란령 아제르바이잔 사이로 빠르게 세를 넓혔고, 소련군이 이란군을 방해하는 방법으로 '\n",
      " '지원해주며 현지에서 쿠데타를 시도했다. 1945년 9월 첫 주 아제르바이잔인 민주당은 이란령 아제르바이잔을 완전 장악하고 사회민주주의 '\n",
      " '개혁을 약속했으며, 이란의 공산당인 투데흐당 지역지부를 전부 해체하겠다고 선포했다. \\\\n\\\\n1945년 9월 말 첫 전당대회에서 '\n",
      " '아제르바이잔인 민주당은 1945년 11월 말까지 각 주에 남아있는 모든 이란 정부 직책을 장악하고 농민민병대를 세울 것이라고 공인했고 '\n",
      " '\"39개 주의 연합으로 이루어진\" 이란령 아제르바이잔이 자치공화국으로 독립할 것이라고 공표했다. 이 단명한 공화국의 초대이자 유일한 '\n",
      " '총리는 아흐마드 코흐다리였다.\\\\n\\\\n소련은 처음엔 이 자치공화국을 지원하고 이란군을 동원한 이란 정부의 통제 시도를 방해하는 등 여러 '\n",
      " '방면으로 지원을 하였으나 이 지원은 오래가지 않았다. 소련군이 철수한 이후 1946년 12월 이란군이 이 지역을 장악하여 피셰바리와 그의 '\n",
      " '내각진들은 소련으로 망명하였다.')\n",
      "Top-4th Passage (Index 1496)\n",
      "('모스크바 평화 조약의 이행은 핀란드인의 강한 정신성으로 인해 문제를 일으켰다. 국경위원회의 소련 회원들조차도 국경의 핀란드쪽에있는 것으로 '\n",
      " '간주 된 남방진동 산업 지역에서의 국경 배치, 대피 된 기계, 기관차 및 철도 차량의 강제 복귀, 어업권과 사이마 운하의 사용과 같이 '\n",
      " '새로운 국경에 의해 야기 된 어려움을 완화시킬 수있는 질문에 대한 융통성은 단순히 소련의 목표에 대한 불신을 높이는 데 '\n",
      " '기여했다.\\\\n\\\\n소련의 태도는 헬싱키, 이반 조토프 새 대사에서 나왔다. 그는 외교적으로 행동했으며 핀란드에서 현실적이거나 상상된 '\n",
      " '소련의 이익을 증진시키기 위해 굳은 동원을했다. 여름과 가을에 그는 소련 외무부 사무실에 핀란드를 마무리하고 소련이 전적으로 핀란드를 '\n",
      " '합병해야한다고 여러 차례 권고했다.\\\\n\\\\n6월 14일, 소련의 폭격기들이 에스토니아 탈린에서 헬싱키로가는 핀란드 여객기 칼레바를 '\n",
      " '격추시켰다. (탑승자 전원 사망)\\\\n\\\\n6월 23일, 소비에트 연방은 핀란드가 영국-캐나다 회사의 케민마 광업권을 철회하여 소비에트 '\n",
      " '연방이 소유한 합작 회사로 이전해야한다고 제안했다. 6월 27일 소련은 올란드 제도에서 비무장화 또는 공동 요새화 노력을 요구했다. '\n",
      " '스웨덴이 7월 8일 독일과 스칸디나비아 군단 이전 협정을 체결한 뒤, 7월 9일 소련 외무 장관은 건초용의 쇠스랑과 유사한 권리를 '\n",
      " '요구했다. 양도권은 9월 6일에 부여되었고 올란드의 비무장화는 10월 11일에 합의되었지만, 케민마에 대한 협상은 계속 진행되었으며 '\n",
      " '핀란드 협상가들은 가능한 한 많이 실속되었다.\\\\n\\\\n소련과 핀란드 공산당 측은, 5월 22일에 핀란드와 소련의 평화와 우정 협회를 '\n",
      " '설립 했고, 소련의 관점을 적극적으로 전파했다. 조토프 대사는 소비에트 대사관에서 사회 지도자들과 매주 회의를 열고 사회 외교관들이 '\n",
      " '공동체 이사회 회의에 참여함으로써 공동체와 매우 긴밀한 연락을 취했다. 협회는 핀란드 정부와 군대를 비판하는 것으로 시작하여 최대 약 '\n",
      " '35,000명의 회원을 확보했다. 그것은 성공으로 시작되어 8월 상반기에 조토프와 정치적으로 많은 지지를 받는 레닌 그라드의 언론 '\n",
      " '운동으로 거의 매일 폭력적인 시위를 조작하기 시작했다. 핀란드 정부는 조토프와 뱌체슬라프 몰로토프의 항의에도 불구하고 이에 대해 강력하게 '\n",
      " '대응하고 소련의 평화와 우정 협회의 주요 회원들을 체포했다. 결국, 소련의 평화와 우정 협회는 마침내 1940년 12월에 '\n",
      " '소멸되었다.\\\\n\\\\n소비에트 연방은 반소비에트 감정으로 인하여 배이뇌 탄네르를 내각에서 퇴출시킬 것을 요구했으며, 8월 15일 결국 '\n",
      " '사임해야했다. 그는 대중 연설에서 소련의 평화와 우정 협회는 제5열으로, 경찰을 책임지고 협회의 단속을 이끌었던 내무부 장관 에른스트 폰 '\n",
      " '본 이라고했지만 리스토 뤼티가 라디오 연설을 한 후 배이뇌 탄네르의 후임으로 내각에 있던 정치인들은 핀란드와 소비에트 연방 사이의 관계를 '\n",
      " '개선하려는 정부의 의지를 밝혔다.\\\\n\\\\n칼리오 대통령은 8월 28일에 뇌졸중으로 일을 할 수 없었고, 11월 27일 사직서를 발표했을 '\n",
      " '때 소련은 칼 구스타브 에밀 만네르헤임 남작등의 반소비에트 감정을 가진 자들이 대통령으로 선출되면 그것은 모스크바 평화 조약의 위반으로 '\n",
      " '간주된다고 말했다.\\\\n\\\\n이 모든 것이 대중에게 소련의 발트 3국 점령을 생각 나게했다. 핀란드인들이 이런 걱정을 한 것은 전혀 '\n",
      " '놀라운 일이 아니었다.')\n",
      "Top-5th Passage (Index 1177)\n",
      "('모스크바 평화 조약의 이행은 핀란드인의 강한 정신성으로 인해 문제를 일으켰다. 국경위원회의 소련 회원들조차도 국경의 핀란드쪽에있는 것으로 '\n",
      " '간주 된 남방진동 산업 지역에서의 국경 배치, 대피 된 기계, 기관차 및 철도 차량의 강제 복귀, 어업권과 사이마 운하의 사용과 같이 '\n",
      " '새로운 국경에 의해 야기 된 어려움을 완화시킬 수있는 질문에 대한 융통성은 단순히 소련의 목표에 대한 불신을 높이는 데 '\n",
      " '기여했다.\\\\n\\\\n소련의 태도는 헬싱키, 이반 조토프 새 대사에서 나왔다. 그는 외교적으로 행동했으며 핀란드에서 현실적이거나 상상된 '\n",
      " '소련의 이익을 증진시키기 위해 굳은 동원을했다. 여름과 가을에 그는 소련 외무부 사무실에 핀란드를 마무리하고 소련이 전적으로 핀란드를 '\n",
      " '합병해야한다고 여러 차례 권고했다.\\\\n\\\\n6월 14일, 소련의 폭격기들이 에스토니아 탈린에서 헬싱키로가는 핀란드 여객기 칼레바를 '\n",
      " '격추시켰다. (탑승자 전원 사망)\\\\n\\\\n6월 23일, 소비에트 연방은 핀란드가 영국-캐나다 회사의 케민마 광업권을 철회하여 소비에트 '\n",
      " '연방이 소유한 합작 회사로 이전해야한다고 제안했다. 6월 27일 소련은 올란드 제도에서 비무장화 또는 공동 요새화 노력을 요구했다. '\n",
      " '스웨덴이 7월 8일 독일과 스칸디나비아 군단 이전 협정을 체결한 뒤, 7월 9일 소련 외무 장관은 건초용의 쇠스랑과 유사한 권리를 '\n",
      " '요구했다. 양도권은 9월 6일에 부여되었고 올란드의 비무장화는 10월 11일에 합의되었지만, 케민마에 대한 협상은 계속 진행되었으며 '\n",
      " '핀란드 협상가들은 가능한 한 많이 실속되었다.\\\\n\\\\n소련과 핀란드 공산당 측은, 5월 22일에 핀란드와 소련의 평화와 우정 협회를 '\n",
      " '설립 했고, 소련의 관점을 적극적으로 전파했다. 조토프 대사는 소비에트 대사관에서 사회 지도자들과 매주 회의를 열고 사회 외교관들이 '\n",
      " '공동체 이사회 회의에 참여함으로써 공동체와 매우 긴밀한 연락을 취했다. 협회는 핀란드 정부와 군대를 비판하는 것으로 시작하여 최대 약 '\n",
      " '35,000명의 회원을 확보했다. 그것은 성공으로 시작되어 8월 상반기에 조토프와 정치적으로 많은 지지를 받는 레닌 그라드의 언론 '\n",
      " '운동으로 거의 매일 폭력적인 시위를 조작하기 시작했다. 핀란드 정부는 조토프와 뱌체슬라프 몰로토프의 항의에도 불구하고 이에 대해 강력하게 '\n",
      " '대응하고 소련의 평화와 우정 협회의 주요 회원들을 체포했다. 결국, 소련의 평화와 우정 협회는 마침내 1940년 12월에 '\n",
      " '소멸되었다.\\\\n\\\\n소비에트 연방은 반소비에트 감정으로 인하여 배이뇌 탄네르를 내각에서 퇴출시킬 것을 요구했으며, 8월 15일 결국 '\n",
      " '사임해야했다. 그는 대중 연설에서 소련의 평화와 우정 협회는 제5열으로, 경찰을 책임지고 협회의 단속을 이끌었던 내무부 장관 에른스트 폰 '\n",
      " '본 이라고했지만 리스토 뤼티가 라디오 연설을 한 후 배이뇌 탄네르의 후임으로 내각에 있던 정치인들은 핀란드와 소비에트 연방 사이의 관계를 '\n",
      " '개선하려는 정부의 의지를 밝혔다.\\\\n\\\\n칼리오 대통령은 8월 28일에 뇌졸중으로 일을 할 수 없었고, 11월 27일 사직서를 발표했을 '\n",
      " '때 소련은 칼 구스타브 에밀 만네르헤임 남작등의 반소비에트 감정을 가진 자들이 대통령으로 선출되면 그것은 모스크바 평화 조약의 위반으로 '\n",
      " '간주된다고 말했다.\\\\n\\\\n이 모든 것이 대중에게 소련의 발트 3국 점령을 생각 나게했다. 핀란드인들이 이런 걱정을 한 것은 전혀 '\n",
      " '놀라운 일이 아니었다.')\n"
     ]
    }
   ],
   "source": [
    "print(f\"[Search Query] {query}\\n\")\n",
    "\n",
    "indices = results.tolist()\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n",
    "    pprint(retriever.dataset[\"context\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
